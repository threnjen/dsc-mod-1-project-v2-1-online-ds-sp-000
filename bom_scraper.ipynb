{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This scraper loads the TMDB data file with IMDB IDs, containing 10,000 movie entries, and scrapes the Box Office Mojo website for any/all of the following:\n",
    "    * budget\n",
    "    * domestic gross\n",
    "    * worldwide gross\n",
    "    * studio\n",
    "    * MPAA rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts our string to a search string\n",
    "def format_title(title):\n",
    "    text = str(title)\n",
    "    result = re.sub(r\"[,@\\'?\\.$%_:â()-]\", \"\", text, flags=re.I)\n",
    "    result = re.sub(r\"\\s+\",\"+\", result, flags = re.I)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert the raw numbers into integers\n",
    "def convert_number(x):\n",
    "    '''Takes in a string formatted number that starts with $ and may include commas, and returns that \n",
    "    number as a whole integer that can be used in calculations'''\n",
    "    try:\n",
    "        x = x[1:]\n",
    "        x = x.replace(',', '')\n",
    "        x = int(x)\n",
    "        return x\n",
    "    except:\n",
    "        print('No number to convert')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that receives the followurl appendation for the IMDB id and follows it\n",
    "def follow_imdb(movie_id):\n",
    "    followurl = 'https://www.boxofficemojo.com/title/' + movie_id\n",
    "    page = requests.get(followurl)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the domestic and foreign gross\n",
    "def gross(movie_page):\n",
    "    try:\n",
    "        search1 = movie_page.find('div', class_='a-section a-spacing-none mojo-performance-summary-table')\n",
    "        dgross = search1.find_all('span', class_='money')[0].text\n",
    "        fgross = search1.find_all('span', class_='money')[1].text\n",
    "        dgross = convert_number(dgross)\n",
    "        fgross = convert_number(fgross)\n",
    "        return dgross, fgross\n",
    "    except:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in the product page and gets the studio name\n",
    "def studio_name(soup):\n",
    "    try:\n",
    "        search1 = soup.find('div', class_='a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile')\n",
    "        search2 = search1.find_all('div', class_='a-section a-spacing-none')[0].find_all(\"span\")\n",
    "        if search2[0].text == 'Domestic Distributor':\n",
    "            studio = search2[1].text.replace('See full company information', '').rstrip()\n",
    "            return studio\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        print('error in studio function')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in the product page and gets the budget\n",
    "def find_budget(soup):\n",
    "    try:\n",
    "        search1 = soup.find('div', class_='a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile')\n",
    "        search2 = search1.find_all('div', class_='a-section a-spacing-none')[2].find_all(\"span\")\n",
    "        if search2[0].text == 'Budget':\n",
    "            budget = search2[1].text\n",
    "            budget = convert_number(budget)\n",
    "            return budget\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        print('error in budget function')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in the product page and gives the MPAA rating\n",
    "def find_mpaa(soup):\n",
    "    try:\n",
    "        search1 = soup.find('div', class_='a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile')\n",
    "        div_search = search1.find_all('div', class_='a-section a-spacing-none')\n",
    "        entries = len(div_search)\n",
    "        \n",
    "        for x in range(0, entries):\n",
    "            search = div_search[x].find_all(\"span\")\n",
    "            if search[0].text == 'MPAA':\n",
    "                rating = search[1].text\n",
    "                return rating\n",
    "            else: continue\n",
    "    except:\n",
    "        print('error in rating function')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Scraping Function\n",
    "\n",
    "def webscraper(scrapingset):\n",
    "    count = 1\n",
    "    length = scrapingset.shape[0]\n",
    "    ts = time.time()\n",
    "    for ind in scrapingset.index:   \n",
    "        movie_id = str(scrapingset['id'][ind])\n",
    "        print(('Item {} / {} - {}').format(count, length, movie_id))\n",
    "        movie_page = follow_imdb(movie_id)\n",
    "        count += 1\n",
    "\n",
    "        rating = find_mpaa(movie_page)\n",
    "        scrapingset['rating'][ind] = rating\n",
    "        \n",
    "        studio = studio_name(movie_page)\n",
    "        scrapingset['studio'][ind] = studio\n",
    "   \n",
    "        dgross, fgross = gross(movie_page)\n",
    "        scrapingset['dom_gross'][ind] = dgross\n",
    "        scrapingset['for_gross'][ind] = fgross\n",
    "    \n",
    "        budget = find_budget(movie_page)\n",
    "        scrapingset['budget'][ind] = budget\n",
    "    \n",
    "    tnow = time.time()\n",
    "    duration = round((tnow - ts), 2)\n",
    "    scrape_average = round(duration/length, 2)\n",
    "    print('{} minutes elapsed'.format(duration/60))\n",
    "    print('{} seconds per item'.format(scrape_average))\n",
    "    return scrapingset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO BEFORE REDOING\n",
    "\n",
    "Round the numbers so they don't have decimal places\n",
    "\n",
    "Add a scraper for rating!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tmdb_imdb files\n",
    "df = pd.read_csv('api_data/tmdb_imdb_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need nothing but the id from this dataframe\n",
    "df.drop(columns=['popularity', 'vote_count', 'genre_ids', 'title', 'vote_average', 'release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We're prepping our dataframe structure for the information that we plan to scrape\n",
    "df['studio'] = ''\n",
    "df['rating'] = ''\n",
    "df['budget'] = ''\n",
    "df['dom_gross'] = ''\n",
    "df['for_gross'] = ''\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Set\n",
    "\n",
    "Before we scrape for 10k returns, we will do a small test scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.DataFrame(columns = ['id', 'rating', 'studio', 'budget', 'dom_gross', 'for_gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['tt1825683', 'tt0349080', 'tt7286456']\n",
    "test1['id'] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1 = webscraper(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A bigger test set\n",
    "test2 = df[0:10]\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = webscraper(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Big Scrape\n",
    "\n",
    "We're ready to do the big scrape!\n",
    "We'll break our frame of 10,000 entries into 5 smaller ones in case of any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[0:2000]\n",
    "df2 = df[2000:4000]\n",
    "df3 = df[4000:6000]\n",
    "df4 = df[6000:8000]\n",
    "df5 = df[8000:10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = webscraper(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = webscraper(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = webscraper(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = webscraper(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = webscraper(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#attach the 5 dataframes together\n",
    "tmdb_bom = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the title as the index\n",
    "tmdb_bom.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the dataframe to a csv\n",
    "tmdb_bom.to_csv('api_data/tmdb_bom_scraped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "\n",
    "Write Docstrings for all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
